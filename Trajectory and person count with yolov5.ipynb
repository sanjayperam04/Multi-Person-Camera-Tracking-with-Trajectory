{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83de5a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ASUS/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-9-30 Python-3.11.3 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\ASUS\\Desktop\\WhatsApp Video 2023-10-03 at 00.28.42_958a94ce.mp4\")\n",
    "cap2 = cv2.VideoCapture(r\"C:\\Users\\ASUS\\Desktop\\WhatsApp Video 2023-10-03 at 00.28.41_7f0f8d8f.mp4\")\n",
    "\n",
    "# Define boundary coordinates (adjust as needed)\n",
    "boundary_x1 = 1  # Top-left x-coordinate\n",
    "boundary_y1 = 1  # Top-left y-coordinate\n",
    "boundary_x2 = 1280  # Bottom-right x-coordinate\n",
    "boundary_y2 = 720  # Bottom-right y-coordinate\n",
    "\n",
    "# Create a dictionary to store the previous positions of each tracked person\n",
    "prev_positions = {}\n",
    "\n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ret, frame = cap.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "    if not ret or not ret2:\n",
    "        break\n",
    "\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    frame_height2, frame_width2, _ = frame2.shape  # Get frame dimensions\n",
    "\n",
    "    # Perform object detection using YOLOv5\n",
    "    results = model(frame)\n",
    "    results2 = model(frame2)\n",
    "\n",
    "    persons = results.pred[0][results.pred[0][:, -1] == 0]\n",
    "    persons2 = results2.pred[0][results2.pred[0][:, -1] == 0]\n",
    "\n",
    "    # Draw directional arrows for each tracked person and count of persons\n",
    "    num_persons = len(persons)\n",
    "    num_persons2 = len(persons2)\n",
    "    cv2.putText(frame, f'PERSONS: {num_persons}', (10, frame_height - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "    cv2.putText(frame2, f'PERSONS: {num_persons2}', (10, frame_height2 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "    for person in persons:\n",
    "        x1, y1, x2, y2, conf = person[:5].cpu().numpy()\n",
    "        center_x = int((x1 + x2) / 2)\n",
    "        center_y = int((y1 + y2) / 2)\n",
    "\n",
    "        # Check if the person has a previous position recorded\n",
    "        if center_x != 0 and center_y != 0:\n",
    "            if center_x < boundary_x1 or center_y < boundary_y1 or center_x > boundary_x2 or center_y > boundary_y2:\n",
    "                continue  # Skip persons outside the boundary\n",
    "\n",
    "            person_id = int(person[5])\n",
    "            if person_id in prev_positions:\n",
    "                prev_x, prev_y = prev_positions[person_id]\n",
    "\n",
    "                # Draw a green line arrow from the previous position to the current position\n",
    "                cv2.arrowedLine(frame, (prev_x, prev_y), (center_x, center_y), (0, 255, 0), 2)\n",
    "\n",
    "            # Store the current position as the previous position\n",
    "            prev_positions[person_id] = (center_x, center_y)\n",
    "\n",
    "            # Display confidence score\n",
    "            cv2.putText(frame, f'Confidence: {conf:.2f}', (center_x, center_y + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "    for person in persons2:\n",
    "        x1, y1, x2, y2, conf = person[:5].cpu().numpy()\n",
    "        center_x = int((x1 + x2) / 2)\n",
    "        center_y = int((y1 + y2) / 2)\n",
    "\n",
    "        # Check if the person has a previous position recorded\n",
    "        if center_x != 0 and center_y != 0:\n",
    "            if center_x < boundary_x1 or center_y < boundary_y1 or center_x > boundary_x2 or center_y > boundary_y2:\n",
    "                continue  # Skip persons outside the boundary\n",
    "\n",
    "            person_id = int(person[5])\n",
    "            if person_id in prev_positions:\n",
    "                prev_x, prev_y = prev_positions[person_id]\n",
    "\n",
    "                # Draw a green line arrow from the previous position to the current position\n",
    "                cv2.arrowedLine(frame2, (prev_x, prev_y), (center_x, center_y), (0, 255, 0), 2)\n",
    "\n",
    "            # Store the current position as the previous position\n",
    "            prev_positions[person_id] = (center_x, center_y)\n",
    "\n",
    "            # Display confidence score\n",
    "            cv2.putText(frame2, f'Confidence: {conf:.2f}', (center_x, center_y + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "    # Draw the boundary\n",
    "    cv2.rectangle(frame, (boundary_x1, boundary_y1), (boundary_x2, boundary_y2), (255, 0, 0), 2)\n",
    "    cv2.rectangle(frame2, (boundary_x1, boundary_y1), (boundary_x2, boundary_y2), (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('Cam 1', frame)\n",
    "    cv2.imshow('Cam 2', frame2)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd5cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
